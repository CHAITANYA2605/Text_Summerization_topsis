{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hljKcqxVjRoI",
        "outputId": "608a9fec-7ebd-4294-e36b-dee28d221a29"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def topsis(input_file, weights, impacts, result_file):\n",
        "    try:\n",
        "        mydata = pd.read_csv(input_file)\n",
        "        validate_numeric_columns(mydata)\n",
        "\n",
        "        weights, impacts = parse_weights_and_impacts(weights, impacts, mydata)\n",
        "        validate_weights_and_impacts(weights, impacts, mydata)\n",
        "\n",
        "        data = mydata.iloc[:, 1:]\n",
        "        normalized_data = normalize_data(data)\n",
        "        weighted_normalized_data = weight_normalized_data(normalized_data, weights)\n",
        "\n",
        "        ideal_best, ideal_worst = compute_ideal_values(weighted_normalized_data, impacts)\n",
        "        separation_best = compute_separation(normalized_data, ideal_best)\n",
        "        separation_worst = compute_separation(normalized_data, ideal_worst)\n",
        "\n",
        "        topsis_score = calculate_topsis_score(separation_worst, separation_best)\n",
        "        rank = calculate_rank(topsis_score)\n",
        "\n",
        "        result_data = create_result_dataframe(mydata, topsis_score, rank)\n",
        "        save_result_to_csv(result_data, result_file)\n",
        "        print(f\"Result saved to {result_file}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: File not found.\")\n",
        "\n",
        "def validate_numeric_columns(mydata):\n",
        "    for col in mydata.columns:\n",
        "        try:\n",
        "            mydata[col] = pd.to_numeric(mydata[col])\n",
        "        except ValueError:\n",
        "            print(f\"Error: Non-numeric values found in column '{col}'.\")\n",
        "            raise ValueError(\"Invalid input file format\")\n",
        "\n",
        "def parse_weights_and_impacts(weights, impacts, mydata):\n",
        "    weights = [float(w) for w in weights.split(',')]\n",
        "    impacts = [i.strip().lower() for i in impacts.split(',')]\n",
        "    return weights, impacts\n",
        "\n",
        "def validate_weights_and_impacts(weights, impacts, mydata):\n",
        "    if len(weights) != len(impacts) or len(weights) != len(mydata.columns) - 1:\n",
        "        print(\"Error: Number of weights, impacts, and columns must be the same.\")\n",
        "        raise ValueError(\"Invalid weights or impacts\")\n",
        "\n",
        "    if not all(impact in ['+', '-'] for impact in impacts):\n",
        "        print(\"Error: Impacts must be either +ve or -ve.\")\n",
        "        raise ValueError(\"Invalid impacts\")\n",
        "\n",
        "def normalize_data(data):\n",
        "    return data.iloc[:, 1:].apply(lambda val: val / np.sqrt(np.sum(val**2)))\n",
        "\n",
        "def weight_normalized_data(normalized_data, weights):\n",
        "    weighted_normalized_data = normalized_data.copy()\n",
        "    for i in range(1, len(weights)):\n",
        "        weighted_normalized_data[data.columns[i]] *= weights[i-1]\n",
        "    return weighted_normalized_data\n",
        "\n",
        "def compute_ideal_values(weighted_normalized_data, impacts):\n",
        "    ideal_best, ideal_worst = [], []\n",
        "    for i in range(len(data.columns)):\n",
        "        if impacts[i] == '+':\n",
        "            ideal_best = pd.to_numeric(weighted_normalized_data.max())\n",
        "            ideal_worst = pd.to_numeric(weighted_normalized_data.min())\n",
        "        else:\n",
        "            ideal_worst = pd.to_numeric(weighted_normalized_data.max())\n",
        "            ideal_best = pd.to_numeric(weighted_normalized_data.min())\n",
        "    return ideal_best, ideal_worst\n",
        "\n",
        "def compute_separation(normalized_data, ideal_values):\n",
        "    return np.sqrt(np.sum((normalized_data - ideal_values.values) ** 2, axis=1))\n",
        "\n",
        "def calculate_topsis_score(separation_worst, separation_best):\n",
        "    return separation_worst / (separation_worst + separation_best)\n",
        "\n",
        "def calculate_rank(topsis_score):\n",
        "    return pd.Series(topsis_score).rank(ascending=False)\n",
        "\n",
        "def create_result_dataframe(mydata, topsis_score, rank):\n",
        "    result_data = mydata.copy()\n",
        "    result_data['Topsis Score'] = topsis_score\n",
        "    result_data['Rank'] = rank\n",
        "    return result_data\n",
        "\n",
        "def save_result_to_csv(result_data, result_file):\n",
        "    result_data.to_csv(result_file, index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if len(sys.argv) != 5:\n",
        "        print(\"Error: Incorrect number of arguments.\")\n",
        "        print(\"Usage: python topsis.py <inputFileName> <Weights> <Impacts> <resultFileName>\")\n",
        "    else:\n",
        "        topsis(sys.argv[1], sys.argv[2], sys.argv[3], sys.argv[4])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRzcmxkVj549"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
